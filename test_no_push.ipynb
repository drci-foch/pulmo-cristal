{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Camelot version: 1.0.0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Optional, List, Any, Tuple\n",
    "from datetime import datetime\n",
    "import PyPDF2\n",
    "from pathlib import Path\n",
    "\n",
    "# Import Camelot\n",
    "try:\n",
    "    import camelot\n",
    "    print(f\"‚úÖ Camelot version: {camelot.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå Camelot non install√©. Ex√©cutez: pip install camelot-py[cv]\")\n",
    "    camelot = None\n",
    "\n",
    "class BaseExtractor:\n",
    "    \"\"\"Classe de base pour tous les extracteurs.\"\"\"\n",
    "    \n",
    "    def __init__(self, logger: Optional[logging.Logger] = None):\n",
    "        self.logger = logger or self._create_default_logger()\n",
    "\n",
    "    def log(self, message: str, level: int = logging.INFO) -> None:\n",
    "        if self.logger:\n",
    "            self.logger.log(level, message)\n",
    "\n",
    "    def _create_default_logger(self) -> logging.Logger:\n",
    "        logger = logging.getLogger(f\"{self.__class__.__name__}\")\n",
    "        \n",
    "        if not logger.handlers:\n",
    "            logger.setLevel(logging.INFO)\n",
    "            console_handler = logging.StreamHandler()\n",
    "            console_handler.setLevel(logging.INFO)\n",
    "            formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "            console_handler.setFormatter(formatter)\n",
    "            logger.addHandler(console_handler)\n",
    "        \n",
    "        return logger\n",
    "\n",
    "    def clean_text(self, text: str) -> str:\n",
    "        \"\"\"Nettoie et normalise le texte.\"\"\"\n",
    "        if not text or pd.isna(text):\n",
    "            return \"\"\n",
    "        cleaned = \" \".join(str(text).split())\n",
    "        replacements = {\n",
    "            \"\\u2019\": \"'\", \"\\u2018\": \"'\", \"\\u201c\": '\"', \"\\u201d\": '\"',\n",
    "            \"\\u2013\": \"-\", \"\\u2014\": \"-\", \"\\u00a0\": \" \",\n",
    "        }\n",
    "        for old, new in replacements.items():\n",
    "            cleaned = cleaned.replace(old, new)\n",
    "        return cleaned.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Camelot version: 1.0.0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Optional, List, Any, Tuple\n",
    "from datetime import datetime\n",
    "import PyPDF2\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    import camelot\n",
    "    print(f\"‚úÖ Camelot version: {camelot.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå Camelot non install√©\")\n",
    "    camelot = None\n",
    "\n",
    "\n",
    "class BaseExtractor:\n",
    "    def __init__(self, logger: Optional[logging.Logger] = None):\n",
    "        self.logger = logger or self._create_default_logger()\n",
    "\n",
    "    def log(self, message: str, level: int = logging.INFO) -> None:\n",
    "        if self.logger:\n",
    "            self.logger.log(level, message)\n",
    "\n",
    "    def _create_default_logger(self) -> logging.Logger:\n",
    "        logger = logging.getLogger(f\"{self.__class__.__name__}\")\n",
    "        if not logger.handlers:\n",
    "            logger.setLevel(logging.INFO)\n",
    "            console_handler = logging.StreamHandler()\n",
    "            console_handler.setLevel(logging.INFO)\n",
    "            formatter = logging.Formatter(\n",
    "                \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    "            )\n",
    "            console_handler.setFormatter(formatter)\n",
    "            logger.addHandler(console_handler)\n",
    "        return logger\n",
    "\n",
    "\n",
    "class SmartGDSExtractor(BaseExtractor):\n",
    "    \"\"\"\n",
    "    Extracteur GDS intelligent qui :\n",
    "    1. Garde les dates comme headers\n",
    "    2. Coupe la table √† FiO2=100\n",
    "    3. Efface les colonnes vides par section\n",
    "    4. Prend l'info la plus r√©cente avec le bon pourcentage FiO2\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, logger: Optional[logging.Logger] = None, debug: bool = False):\n",
    "        super().__init__(logger=logger)\n",
    "        self.debug = debug\n",
    "\n",
    "        if camelot is None:\n",
    "            raise ImportError(\"Camelot requis: pip install camelot-py[cv]\")\n",
    "\n",
    "    def extract_gds_data_from_pdf(self, pdf_path: str, pages: str = \"all\") -> Dict[str, Any]:\n",
    "        \"\"\"Extrait les donn√©es GDS du PDF avec la nouvelle logique.\"\"\"\n",
    "        if not Path(pdf_path).exists():\n",
    "            self.log(f\"Fichier non trouv√©: {pdf_path}\", level=logging.ERROR)\n",
    "            return {}\n",
    "\n",
    "        try:\n",
    "            # Extraction Camelot\n",
    "            tables = camelot.read_pdf(pdf_path, pages=pages, flavor='stream')\n",
    "            self.log(f\"Trouv√© {len(tables)} tables\")\n",
    "\n",
    "            # Trouve la table GDS principale\n",
    "            gds_table = self._find_main_gds_table(tables)\n",
    "            if gds_table is None:\n",
    "                self.log(\"Aucune table GDS trouv√©e\", level=logging.WARNING)\n",
    "                return {}\n",
    "\n",
    "            # Applique la nouvelle logique de traitement\n",
    "            return self._process_gds_table_smart(gds_table)\n",
    "\n",
    "        except Exception as e:\n",
    "            self.log(f\"Erreur extraction: {str(e)}\", level=logging.ERROR)\n",
    "            return {}\n",
    "\n",
    "    def _find_main_gds_table(self, tables) -> Optional[object]:\n",
    "        \"\"\"Trouve la table GDS principale (la plus compl√®te).\"\"\"\n",
    "        best_table = None\n",
    "        best_score = 0\n",
    "\n",
    "        for table in tables:\n",
    "            df = table.df\n",
    "            table_text = df.to_string().lower()\n",
    "\n",
    "            # Score bas√© sur indicateurs GDS\n",
    "            indicators = ['fio2', 'ph', 'paco2', 'pao2', 'sao2', 'peep', 'co3h', 'mmhg']\n",
    "            score = sum(1 for ind in indicators if ind in table_text)\n",
    "\n",
    "            # Bonus pour structure attendue\n",
    "            if 'fio2<100' in table_text and 'fio2=100' in table_text:\n",
    "                score += 5\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_table = table\n",
    "\n",
    "        if self.debug and best_table is not None:\n",
    "            print(f\"üéØ Table GDS s√©lectionn√©e (score: {best_score})\")\n",
    "            print(f\"   Shape: {best_table.df.shape}\")\n",
    "\n",
    "        return best_table\n",
    "\n",
    "\n",
    "    def _process_gds_table_smart(self, table) -> Dict[str, Any]:\n",
    "        \"\"\"Version corrig√©e avec gestion des cas sans split.\"\"\"\n",
    "        df = table.df.copy()\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"\\nüîç Traitement table GDS:\")\n",
    "            print(f\"   Shape originale: {df.shape}\")\n",
    "\n",
    "        # √âtape 1: Extrait les headers (dates/heures)\n",
    "        headers = self._extract_headers(df)\n",
    "\n",
    "        # √âtape 2: Trouve la ligne de s√©paration FiO2=100\n",
    "        split_row = self._find_fio2_100_split(df)\n",
    "\n",
    "        if split_row is None:\n",
    "            # Cas particulier : pas de split trouv√©, traite tout comme une section\n",
    "            self.log(\"Aucun split FiO2=100 d√©tect√©, analyse comme section mixte\", level=logging.WARNING)\n",
    "            return self._process_mixed_section(df, headers)\n",
    "\n",
    "        # √âtape 3: Divise la table\n",
    "        fio2_less_100_df = df.iloc[:split_row].copy()\n",
    "        fio2_100_df = df.iloc[split_row:].copy()\n",
    "\n",
    "        # Important: Ajoute les headers aux deux sections\n",
    "        if len(headers) > 0:\n",
    "            header_rows = df.iloc[:2].copy()  # Lignes dates et heures\n",
    "            \n",
    "            # Pour FiO2=100, ajoute les headers au d√©but\n",
    "            fio2_100_df = pd.concat([header_rows, fio2_100_df], ignore_index=True)\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"   Split √† la ligne {split_row}\")\n",
    "            print(f\"   FiO2<100 shape: {fio2_less_100_df.shape}\")\n",
    "            print(f\"   FiO2=100 shape: {fio2_100_df.shape} (headers ajout√©s)\")\n",
    "\n",
    "        # √âtape 4: Traite chaque section si elle n'est pas vide\n",
    "        all_data = []\n",
    "        \n",
    "        if len(fio2_less_100_df) > 0:\n",
    "            fio2_less_100_clean, fio2_less_100_headers = self._remove_empty_columns_per_section(\n",
    "                fio2_less_100_df, headers, \"FiO2<100\"\n",
    "            )\n",
    "            fio2_less_100_data = self._extract_section_data_smart(\n",
    "                fio2_less_100_clean, fio2_less_100_headers, \"FiO2<100\"\n",
    "            )\n",
    "            all_data.extend(fio2_less_100_data)\n",
    "        \n",
    "        if len(fio2_100_df) > 0:\n",
    "            fio2_100_clean, fio2_100_headers = self._remove_empty_columns_per_section(\n",
    "                fio2_100_df, headers, \"FiO2=100\"\n",
    "            )\n",
    "            fio2_100_data = self._extract_section_data_smart(\n",
    "                fio2_100_clean, fio2_100_headers, \"FiO2=100\"\n",
    "            )\n",
    "            all_data.extend(fio2_100_data)\n",
    "\n",
    "        # √âtape 5: S√©lectionne les meilleures donn√©es\n",
    "        if all_data:\n",
    "            return self._select_best_data_smart(all_data)\n",
    "        else:\n",
    "            return {}\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "    def _process_mixed_section(self, df: pd.DataFrame, headers: List[Dict]) -> Dict[str, Any]:\n",
    "        \"\"\"Traite une table mixte en analysant les colonnes individuellement.\"\"\"\n",
    "        if self.debug:\n",
    "            print(\"   üîÑ Analyse intelligente des colonnes par type FiO2\")\n",
    "        \n",
    "        # Nettoie les colonnes vides\n",
    "        df_clean, clean_headers = self._remove_empty_columns_per_section(df, headers, \"Mixte\")\n",
    "        \n",
    "        # NOUVELLE APPROCHE: Analyse chaque colonne individuellement\n",
    "        all_data = []\n",
    "        \n",
    "        for header in clean_headers:\n",
    "            col_idx = header['column_index']\n",
    "            timestamp = f\"{header['date']} {header['time']}\".strip()\n",
    "            \n",
    "            if self.debug:\n",
    "                print(f\"   üìä Analyse colonne {col_idx} ({timestamp})\")\n",
    "            \n",
    "            # D√©termine le type de cette colonne sp√©cifique\n",
    "            column_type, fio2_percentage = self._analyze_column_type(df_clean, col_idx)\n",
    "            \n",
    "            if column_type and fio2_percentage:\n",
    "                if self.debug:\n",
    "                    print(f\"      ‚Üí Type d√©tect√©: {column_type}, FiO2: {fio2_percentage}%\")\n",
    "                \n",
    "                # Extrait les donn√©es pour cette colonne sp√©cifique\n",
    "                column_data = self._extract_column_data(\n",
    "                    df_clean, col_idx, timestamp, column_type, fio2_percentage\n",
    "                )\n",
    "                \n",
    "                if column_data:\n",
    "                    all_data.append(column_data)\n",
    "            else:\n",
    "                if self.debug:\n",
    "                    print(f\"      ‚Üí Aucune donn√©es dans cette colonne\")\n",
    "        \n",
    "        if all_data:\n",
    "            return self._select_best_data_smart(all_data)\n",
    "        else:\n",
    "            return {}\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _extract_column_data(\n",
    "        self, \n",
    "        df: pd.DataFrame, \n",
    "        col_idx: int, \n",
    "        timestamp: str, \n",
    "        fio2_type: str, \n",
    "        fio2_percentage: float\n",
    "    ) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Extrait les donn√©es m√©dicales d'une colonne sp√©cifique.\"\"\"\n",
    "        \n",
    "        # Trouve les lignes de param√®tres\n",
    "        param_rows = self._find_medical_parameter_rows(df)\n",
    "        \n",
    "        data_entry = {\n",
    "            'timestamp': timestamp,\n",
    "            'fio2_type': fio2_type,\n",
    "            'fio2_percentage': fio2_percentage,\n",
    "            'column_index': col_idx\n",
    "        }\n",
    "        \n",
    "        extracted_params = []\n",
    "        \n",
    "        # Extrait chaque param√®tre\n",
    "        for param_name, row_idx in param_rows.items():\n",
    "            if row_idx < len(df) and col_idx < len(df.columns):\n",
    "                numeric_value = self._extract_parameter_value_from_row(\n",
    "                    df, row_idx, col_idx, param_name\n",
    "                )\n",
    "                \n",
    "                if numeric_value is not None:\n",
    "                    data_entry[param_name] = numeric_value\n",
    "                    extracted_params.append(param_name)\n",
    "        \n",
    "        if len(extracted_params) >= 3:  # Au moins 3 param√®tres pour √™tre valide\n",
    "            if self.debug:\n",
    "                print(f\"      ‚úÖ {timestamp} ({fio2_type}, {fio2_percentage}%): \"\n",
    "                    f\"{len(extracted_params)} params [{', '.join(extracted_params)}]\")\n",
    "            return data_entry\n",
    "        else:\n",
    "            if self.debug:\n",
    "                print(f\"      ‚ùå {timestamp}: seulement {len(extracted_params)} params\")\n",
    "            return None\n",
    "\n",
    "    def _analyze_column_type(self, df: pd.DataFrame, col_idx: int) -> Tuple[Optional[str], Optional[float]]:\n",
    "        \"\"\"Analyse une colonne sp√©cifique pour d√©terminer son type FiO2.\"\"\"\n",
    "        \n",
    "        # Compte les valeurs m√©dicales pr√©sentes dans cette colonne\n",
    "        medical_values = 0\n",
    "        has_percentage = False\n",
    "        found_percentage = None\n",
    "        \n",
    "        for row_idx, row in df.iterrows():\n",
    "            if col_idx < len(row):\n",
    "                cell_value = str(row.iloc[col_idx]).strip()\n",
    "                \n",
    "                if cell_value and cell_value not in ['nan', '']:\n",
    "                    # Cherche des valeurs m√©dicales\n",
    "                    if re.search(r'\\d+(?:\\.\\d+)?\\s*(?:mmhg|mmol|%|cm)', cell_value.lower()):\n",
    "                        medical_values += 1\n",
    "                    \n",
    "                    # Cherche pH\n",
    "                    if re.search(r'\\d\\.\\d{2}', cell_value):\n",
    "                        medical_values += 1\n",
    "                    \n",
    "                    # Cherche des pourcentages FiO2 sp√©cifiques\n",
    "                    percentage_match = re.search(r'(\\d+)\\s*%', cell_value)\n",
    "                    if percentage_match:\n",
    "                        pct = float(percentage_match.group(1))\n",
    "                        # V√©rifie si c'est sur une ligne FiO2\n",
    "                        row_text = ' '.join(str(c) for c in row if str(c).strip()).lower()\n",
    "                        if 'fio2' in row_text or 'pourcentage' in row_text:\n",
    "                            has_percentage = True\n",
    "                            found_percentage = pct\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"      Colonne {col_idx}: {medical_values} valeurs m√©dicales, \"\n",
    "                f\"pourcentage: {found_percentage}%\")\n",
    "        \n",
    "        # D√©termine le type bas√© sur l'analyse\n",
    "        if medical_values >= 3:  # Au moins 3 param√®tres m√©dicaux\n",
    "            if has_percentage and found_percentage and found_percentage < 100:\n",
    "                return \"FiO2<100\", found_percentage\n",
    "            elif has_percentage and found_percentage == 100:\n",
    "                return \"FiO2=100\", found_percentage\n",
    "            else:\n",
    "                # Pas de pourcentage explicite, devine bas√© sur les valeurs PaO2\n",
    "                pao2_value = self._get_pao2_from_column(df, col_idx)\n",
    "                if pao2_value and pao2_value > 300:  # PaO2 √©lev√© sugg√®re FiO2=100\n",
    "                    return \"FiO2=100\", 100.0\n",
    "                else:\n",
    "                    return \"FiO2<100\", 21.0  # D√©faut air ambiant\n",
    "        \n",
    "        return None, None\n",
    "\n",
    "    def _get_pao2_from_column(self, df: pd.DataFrame, col_idx: int) -> Optional[float]:\n",
    "        \"\"\"Extrait la valeur PaO2 d'une colonne pour aider √† d√©terminer le type.\"\"\"\n",
    "        for row_idx, row in df.iterrows():\n",
    "            row_text = ' '.join(str(c) for c in row if str(c).strip()).lower()\n",
    "            if 'pao2' in row_text and col_idx < len(row):\n",
    "                cell_value = str(row.iloc[col_idx]).strip()\n",
    "                pao2_match = re.search(r'(\\d+(?:\\.\\d+)?)\\s*mmhg', cell_value.lower())\n",
    "                if pao2_match:\n",
    "                    return float(pao2_match.group(1))\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "    def _extract_headers(self, df: pd.DataFrame) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Extrait les headers (dates/heures) de la table.\n",
    "\n",
    "        Returns:\n",
    "            Liste de dictionnaires avec 'date', 'time', 'column_index'\n",
    "        \"\"\"\n",
    "        headers = []\n",
    "\n",
    "        # Cherche dans les premi√®res lignes\n",
    "        for row_idx in range(min(3, len(df))):\n",
    "            row = df.iloc[row_idx]\n",
    "\n",
    "            for col_idx, cell in enumerate(row):\n",
    "                cell_str = str(cell).strip()\n",
    "\n",
    "                if not cell_str or cell_str == 'nan':\n",
    "                    continue\n",
    "\n",
    "                # Cherche des dates\n",
    "                date_match = re.search(r'(\\d{2}/\\d{2}/\\d{4})', cell_str)\n",
    "                time_match = re.search(r'(\\d{2}:\\d{2})', cell_str)\n",
    "\n",
    "                if date_match or time_match:\n",
    "                    # Trouve ou cr√©e l'entr√©e header pour cette colonne\n",
    "                    header_entry = next(\n",
    "                        (h for h in headers if h['column_index'] == col_idx), None\n",
    "                    )\n",
    "\n",
    "                    if header_entry is None:\n",
    "                        header_entry = {'column_index': col_idx, 'date': '', 'time': ''}\n",
    "                        headers.append(header_entry)\n",
    "\n",
    "                    if date_match:\n",
    "                        header_entry['date'] = date_match.group(1)\n",
    "                    if time_match:\n",
    "                        header_entry['time'] = time_match.group(1)\n",
    "\n",
    "        # Trie par index de colonne\n",
    "        headers.sort(key=lambda x: x['column_index'])\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"   üìÖ Headers extraits: {len(headers)}\")\n",
    "            for h in headers:\n",
    "                print(f\"      Col {h['column_index']}: {h['date']} {h['time']}\")\n",
    "\n",
    "        return headers\n",
    "\n",
    "    def _find_fio2_100_split(self, df: pd.DataFrame) -> Optional[int]:\n",
    "        \"\"\"Trouve la VRAIE ligne de s√©paration FiO2=100, pas le titre g√©n√©ral.\"\"\"\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"   üîç Recherche du split FiO2=100 dans {len(df)} lignes\")\n",
    "            # Debug: affiche quelques lignes pour comprendre la structure\n",
    "            for i in range(min(len(df), 12)):\n",
    "                row_text = ' '.join(str(cell) for cell in df.iloc[i] if str(cell).strip())[:100]\n",
    "                print(f\"      Ligne {i}: {row_text}\")\n",
    "        \n",
    "        # √âTAPE 1: Cherche la ligne qui marque le D√âBUT des donn√©es FiO2=100\n",
    "        # Cette ligne contient souvent \"FiO2=100\" ET \"pH\" ou d'autres param√®tres\n",
    "        for idx in range(1, len(df)):  # Skip ligne 0 (titre g√©n√©ral)\n",
    "            row_text = ' '.join(str(cell) for cell in df.iloc[idx] if str(cell).strip()).lower()\n",
    "            \n",
    "            # Patterns sp√©cifiques pour la ligne de transition\n",
    "            transition_patterns = [\n",
    "                r'fio2\\s*=\\s*100.*ph',      # \"FiO2=100 : pH\" \n",
    "                r'fio2\\s*=\\s*100\\s*:',      # \"FiO2=100 :\"\n",
    "                r'^fio2\\s*=\\s*100\\s*$',     # Ligne avec juste \"FiO2=100\"\n",
    "                r'.*fio2\\s*=\\s*100.*',      # Toute ligne contenant \"FiO2=100\"\n",
    "            ]\n",
    "            \n",
    "            for pattern in transition_patterns:\n",
    "                if re.search(pattern, row_text):\n",
    "                    if self.debug:\n",
    "                        print(f\"   ‚úÖ Split FiO2=100 trouv√© ligne {idx}: {row_text[:80]}\")\n",
    "                    return idx\n",
    "        \n",
    "        # √âTAPE 2: M√©thode alternative - cherche le changement de structure\n",
    "        # Apr√®s les donn√©es FiO2<100, il y a souvent une ligne diff√©rente avant FiO2=100\n",
    "        for idx in range(2, len(df) - 2):\n",
    "            current_row = ' '.join(str(cell) for cell in df.iloc[idx] if str(cell).strip()).lower()\n",
    "            next_row = ' '.join(str(cell) for cell in df.iloc[idx + 1] if str(cell).strip()).lower()\n",
    "            \n",
    "            # Cherche une ligne avec \"fio2=100\" suivie d'une ligne avec des param√®tres\n",
    "            if ('fio2=100' in current_row and \n",
    "                any(param in next_row for param in ['ph', 'paco2', 'pao2', 'mmhg'])):\n",
    "                if self.debug:\n",
    "                    print(f\"   ‚úÖ Split alternatif ligne {idx}: {current_row[:60]}\")\n",
    "                return idx\n",
    "                \n",
    "        # √âTAPE 3: Cherche par analyse de contenu - d√©tecte le changement de pattern\n",
    "        # Les lignes FiO2<100 ont des donn√©es, puis il y a une transition\n",
    "        data_lines = []\n",
    "        for idx in range(1, len(df)):\n",
    "            row_text = ' '.join(str(cell) for cell in df.iloc[idx] if str(cell).strip())\n",
    "            \n",
    "            # Compte les donn√©es m√©dicales dans cette ligne\n",
    "            medical_count = len(re.findall(r'\\d+(?:\\.\\d+)?\\s*(?:mmhg|mmol|%|cm)', row_text.lower()))\n",
    "            medical_count += len(re.findall(r'\\d\\.\\d{2}', row_text))  # pH\n",
    "            \n",
    "            data_lines.append((idx, medical_count, row_text.lower()))\n",
    "            \n",
    "            if self.debug and medical_count > 0:\n",
    "                print(f\"      Ligne {idx}: {medical_count} valeurs m√©dicales\")\n",
    "        \n",
    "        # Cherche le point o√π le pattern change\n",
    "        for i in range(1, len(data_lines) - 1):\n",
    "            idx, count, text = data_lines[i]\n",
    "            \n",
    "            # Si cette ligne contient \"fio2=100\" et que les lignes suivantes ont des donn√©es\n",
    "            if 'fio2=100' in text and count == 0:\n",
    "                # V√©rifie que les lignes suivantes ont des donn√©es\n",
    "                following_data = sum(data_lines[j][1] for j in range(i + 1, min(i + 4, len(data_lines))))\n",
    "                if following_data > 3:  # Au moins quelques param√®tres dans les lignes suivantes\n",
    "                    if self.debug:\n",
    "                        print(f\"   ‚úÖ Split par analyse ligne {idx}: changement de pattern d√©tect√©\")\n",
    "                    return idx\n",
    "        \n",
    "        if self.debug:\n",
    "            print(\"   ‚ùå Aucun split FiO2=100 trouv√©\")\n",
    "        return None\n",
    "\n",
    "    def _remove_empty_columns_per_section(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        headers: List[Dict],\n",
    "        section_type: str\n",
    "    ) -> Tuple[pd.DataFrame, List[Dict]]:\n",
    "        \"\"\"Version am√©lior√©e pour d√©tecter correctement les colonnes avec donn√©es.\"\"\"\n",
    "        # Colonnes √† garder : toujours la colonne 0 (labels)\n",
    "        columns_to_keep = {0}\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"   üîç Analyse colonnes pour {section_type}:\")\n",
    "            print(f\"      DataFrame shape: {df.shape}\")\n",
    "\n",
    "        # Analyser chaque colonne pour voir si elle a du contenu m√©dical\n",
    "        for col_idx in range(1, len(df.columns)):\n",
    "            col_content = []\n",
    "            numeric_values = 0\n",
    "            medical_units = 0\n",
    "            \n",
    "            for row_idx in range(len(df)):\n",
    "                cell_value = str(df.iloc[row_idx, col_idx]).strip()\n",
    "                if cell_value and cell_value != 'nan':\n",
    "                    col_content.append(cell_value.lower())\n",
    "                    \n",
    "                    # Compte les valeurs num√©riques\n",
    "                    if re.search(r'\\d+(?:\\.\\d+)?', cell_value):\n",
    "                        numeric_values += 1\n",
    "                    \n",
    "                    # Compte les unit√©s m√©dicales\n",
    "                    if re.search(r'mmhg|mmol|%|cm.*eau', cell_value.lower()):\n",
    "                        medical_units += 1\n",
    "\n",
    "            col_text = ' '.join(col_content)\n",
    "\n",
    "            # Crit√®res plus stricts pour garder une colonne\n",
    "            has_timestamps = bool(re.search(r'\\d{2}/\\d{2}/\\d{4}|\\d{2}:\\d{2}', col_text))\n",
    "            has_medical_values = numeric_values >= 2  # Au moins 2 valeurs num√©riques\n",
    "            has_medical_units = medical_units >= 1    # Au moins 1 unit√© m√©dicale\n",
    "            has_ph_values = bool(re.search(r'\\d\\.\\d{2}', col_text))  # pH typique\n",
    "\n",
    "            should_keep = has_timestamps or (has_medical_values and (has_medical_units or has_ph_values))\n",
    "\n",
    "            if should_keep:\n",
    "                columns_to_keep.add(col_idx)\n",
    "                \n",
    "            if self.debug:\n",
    "                print(f\"      Col {col_idx}: nums={numeric_values}, units={medical_units}, \"\n",
    "                    f\"timestamps={has_timestamps}, pH={has_ph_values} -> {'GARD√âE' if should_keep else 'SUPPRIM√âE'}\")\n",
    "                if should_keep:\n",
    "                    print(f\"         Contenu: {col_text[:80]}...\")\n",
    "\n",
    "        # Filtre le DataFrame\n",
    "        columns_to_keep = sorted(list(columns_to_keep))\n",
    "        df_clean = df.iloc[:, columns_to_keep]\n",
    "\n",
    "        # Met √† jour les headers\n",
    "        old_to_new_mapping = {old_idx: new_idx for new_idx, old_idx in enumerate(columns_to_keep)}\n",
    "\n",
    "        updated_headers = []\n",
    "        for header in headers:\n",
    "            if header['column_index'] in old_to_new_mapping:\n",
    "                new_header = header.copy()\n",
    "                new_header['column_index'] = old_to_new_mapping[header['column_index']]\n",
    "                new_header['original_column'] = header['column_index']\n",
    "                updated_headers.append(new_header)\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"   üßπ {section_type} nettoyage: {df.shape} -> {df_clean.shape}\")\n",
    "            print(f\"      Colonnes gard√©es: {columns_to_keep}\")\n",
    "            print(f\"      Headers finaux: {[(h['original_column'], h['date'], h['time']) for h in updated_headers]}\")\n",
    "\n",
    "        return df_clean, updated_headers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _extract_section_data_smart(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        headers: List[Dict],\n",
    "        section_type: str\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Extrait les donn√©es d'une section avec la logique am√©lior√©e.\n",
    "        \"\"\"\n",
    "        if self.debug:\n",
    "            print(f\"\\n   üìä Extraction section {section_type}:\")\n",
    "            print(f\"      Shape: {df.shape}\")\n",
    "\n",
    "        data_entries = []\n",
    "\n",
    "        # Trouve les pourcentages FiO2 pour cette section\n",
    "        fio2_percentages = self._extract_fio2_percentages(df, section_type)\n",
    "\n",
    "        # Trouve les lignes de param√®tres m√©dicaux\n",
    "        param_rows = self._find_medical_parameter_rows(df)\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"      FiO2 percentages: {fio2_percentages}\")\n",
    "            print(f\"      Param rows: {list(param_rows.keys())}\")\n",
    "\n",
    "        # Pour chaque header (timestamp), extrait les valeurs\n",
    "        for header in headers:\n",
    "            col_idx = header['column_index']\n",
    "\n",
    "            if col_idx >= len(df.columns):\n",
    "                continue\n",
    "\n",
    "            timestamp = f\"{header['date']} {header['time']}\".strip()\n",
    "            if not timestamp:\n",
    "                continue\n",
    "\n",
    "            # D√©termine le pourcentage FiO2 pour cette colonne\n",
    "            fio2_percentage = self._get_fio2_for_column(\n",
    "                fio2_percentages, col_idx, section_type\n",
    "            )\n",
    "\n",
    "            data_entry = {\n",
    "                'timestamp': timestamp,\n",
    "                'fio2_type': section_type,\n",
    "                'fio2_percentage': fio2_percentage,\n",
    "                'column_index': col_idx\n",
    "            }\n",
    "\n",
    "            # Extrait les valeurs des param√®tres pour cette colonne\n",
    "            has_medical_data = False\n",
    "            extracted_params = []\n",
    "\n",
    "            for param_name, row_idx in param_rows.items():\n",
    "                if row_idx < len(df) and col_idx < len(df.columns):\n",
    "                    # Am√©lioration: extraction cibl√©e par param√®tre\n",
    "                    numeric_value = self._extract_parameter_value_from_row(\n",
    "                        df, row_idx, col_idx, param_name\n",
    "                    )\n",
    "\n",
    "                    if numeric_value is not None:\n",
    "                        data_entry[param_name] = numeric_value\n",
    "                        has_medical_data = True\n",
    "                        extracted_params.append(param_name)\n",
    "                        if self.debug:\n",
    "                            print(f\"      ‚Üí {param_name}: {numeric_value} (ligne {row_idx}, col {col_idx}) ‚úì\")\n",
    "                    else:\n",
    "                        if self.debug:\n",
    "                            cell_value = str(df.iloc[row_idx, col_idx]).strip()\n",
    "                            print(f\"      ‚Üí {param_name}: √âCHEC - cellule='{cell_value}' (ligne {row_idx}, col {col_idx}) ‚úó\")\n",
    "\n",
    "            # Ajoute seulement si on a des donn√©es m√©dicales\n",
    "            if has_medical_data:\n",
    "                data_entries.append(data_entry)\n",
    "                if self.debug:\n",
    "                    print(f\"      ‚úÖ {timestamp}: {len(extracted_params)} params [{', '.join(extracted_params)}]\")\n",
    "\n",
    "        return data_entries\n",
    "\n",
    "\n",
    "    def _extract_parameter_value_from_row(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        row_idx: int,\n",
    "        col_idx: int,\n",
    "        param_name: str,\n",
    "    ) -> Optional[float]:\n",
    "        \"\"\"\n",
    "        Extrait la valeur sp√©cifique d'un param√®tre avec recherche √©tendue.\n",
    "        \"\"\"\n",
    "        if row_idx >= len(df) or col_idx >= len(df.columns):\n",
    "            return None\n",
    "\n",
    "        cell_value = str(df.iloc[row_idx, col_idx]).strip()\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"         Analyse cellule [{row_idx}, {col_idx}] pour {param_name}: '{cell_value}'\")\n",
    "\n",
    "        # NOUVELLE LOGIQUE: Recherche √©tendue si cellule vide\n",
    "        search_cells = [cell_value]\n",
    "        \n",
    "        if not cell_value or cell_value in [\"nan\", \"\", \"√Ä ajouter\"]:\n",
    "            # Cherche dans un rayon de 3 lignes autour\n",
    "            for offset in [1, -1, 2, -2, 3]:\n",
    "                check_row = row_idx + offset\n",
    "                if 0 <= check_row < len(df):\n",
    "                    next_cell = str(df.iloc[check_row, col_idx]).strip()\n",
    "                    if next_cell and next_cell not in [\"nan\", \"\", \"√Ä ajouter\"]:\n",
    "                        search_cells.append(next_cell)\n",
    "                        if self.debug:\n",
    "                            print(f\"         ‚Üí Cellule alternative ligne {check_row}: '{next_cell}'\")\n",
    "\n",
    "        # Teste chaque cellule trouv√©e\n",
    "        for cell_candidate in search_cells:\n",
    "            if not cell_candidate:\n",
    "                continue\n",
    "                \n",
    "            extracted_value = self._extract_parameter_by_type(cell_candidate, param_name)\n",
    "            \n",
    "            if extracted_value is not None:\n",
    "                if self.debug:\n",
    "                    print(f\"         ‚Üí Valeur extraite pour {param_name}: {extracted_value}\")\n",
    "                return extracted_value\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"         ‚Üí Aucune valeur valide trouv√©e pour {param_name}\")\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def _extract_parameter_by_type(self, cell_value: str, param_name: str) -> Optional[float]:\n",
    "        \"\"\"Extraction sp√©cialis√©e par type de param√®tre.\"\"\"\n",
    "        \n",
    "        if param_name == \"pH\":\n",
    "            ph_match = re.search(r\"(\\d+\\.\\d{1,2})\", cell_value)\n",
    "            if ph_match:\n",
    "                value = float(ph_match.group(1))\n",
    "                if 6.5 <= value <= 8.0:\n",
    "                    return value\n",
    "\n",
    "        elif param_name in [\"PaCO2\", \"PaO2\"]:\n",
    "            # Cherche avec unit√© mmHg d'abord\n",
    "            pressure_match = re.search(r\"(\\d+(?:\\.\\d+)?)\\s*mmhg\", cell_value.lower())\n",
    "            if pressure_match:\n",
    "                value = float(pressure_match.group(1))\n",
    "                if self.debug:\n",
    "                    print(f\"         ‚Üí Trouv√© {param_name} avec mmHg: {value}\")\n",
    "                return value\n",
    "            \n",
    "            # Cherche un nombre seul SEULEMENT si pas d'unit√© parasite\n",
    "            if not re.search(r\"mmol|%|cm\", cell_value.lower()):\n",
    "                num_match = re.search(r\"(\\d+(?:\\.\\d+)?)\", cell_value)\n",
    "                if num_match:\n",
    "                    value = float(num_match.group(1))\n",
    "                    if self.debug:\n",
    "                        print(f\"         ‚Üí Trouv√© {param_name} sans unit√©: {value}\")\n",
    "                    \n",
    "                    # Validation stricte selon le param√®tre\n",
    "                    if param_name == \"PaCO2\" and 10 <= value <= 100:\n",
    "                        return value\n",
    "                    elif param_name == \"PaO2\" and 30 <= value <= 600:\n",
    "                        return value\n",
    "\n",
    "        elif param_name == \"CO3H\":\n",
    "            # Cherche avec unit√© mmol d'abord\n",
    "            co3h_match = re.search(r\"(\\d+(?:\\.\\d+)?)\\s*mmol\", cell_value.lower())\n",
    "            if co3h_match:\n",
    "                value = float(co3h_match.group(1))\n",
    "                if 10 <= value <= 35:\n",
    "                    return value\n",
    "\n",
    "        elif param_name == \"SaO2\":\n",
    "            sao2_match = re.search(r\"(\\d+(?:\\.\\d+)?)\\s*%\", cell_value)\n",
    "            if sao2_match:\n",
    "                value = float(sao2_match.group(1))\n",
    "                if 70 <= value <= 100:\n",
    "                    return value\n",
    "\n",
    "        elif param_name == \"PEEP\":\n",
    "            peep_match = re.search(r\"(\\d+(?:\\.\\d+)?)\\s*cm\", cell_value.lower())\n",
    "            if peep_match:\n",
    "                value = float(peep_match.group(1))\n",
    "                if 0 <= value <= 25:\n",
    "                    return value\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _is_value_plausible(self, param_name: str, value: float) -> bool:\n",
    "        \"\"\"V√©rifie si une valeur est plausible pour un param√®tre donn√©.\"\"\"\n",
    "        plausible_ranges = {\n",
    "            \"pH\": (6.5, 8.0),\n",
    "            \"PaCO2\": (10, 100),\n",
    "            \"PaO2\": (30, 600),\n",
    "            \"SaO2\": (70, 100),\n",
    "            \"CO3H\": (10, 35),\n",
    "            \"PEEP\": (0, 25),\n",
    "        }\n",
    "        if param_name in plausible_ranges:\n",
    "            min_val, max_val = plausible_ranges[param_name]\n",
    "            return min_val <= value <= max_val\n",
    "        return True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _extract_fio2_percentages(self, df: pd.DataFrame, section_type: str) -> Dict[int, float]:\n",
    "        \"\"\"Version corrig√©e pour mieux identifier les pourcentages FiO2.\"\"\"\n",
    "        percentages = {}\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"      Recherche pourcentages FiO2 dans section {section_type}\")\n",
    "\n",
    "        # Patterns plus sp√©cifiques selon le type de section\n",
    "        if section_type == \"FiO2<100\":\n",
    "            fio2_indicators = [\n",
    "                \"fio2<100.*pourcentage\",\n",
    "                \"fio2.*<.*100.*pourcentage\", \n",
    "                \"pourcentage.*:\",  # si isol√© dans section FiO2<100\n",
    "            ]\n",
    "        else:  # FiO2=100\n",
    "            fio2_indicators = [\n",
    "                \"fio2=100\",\n",
    "                \"fio2.*=.*100\",\n",
    "            ]\n",
    "\n",
    "        # √âTAPE 1: Identifier les lignes FiO2 sp√©cifiques\n",
    "        fio2_indicator_rows = []\n",
    "        \n",
    "        for row_idx, row in df.iterrows():\n",
    "            row_text = \" \".join(str(cell) for cell in row if str(cell).strip()).lower()\n",
    "            \n",
    "            if any(re.search(indicator, row_text) for indicator in fio2_indicators):\n",
    "                fio2_indicator_rows.append(row_idx)\n",
    "                if self.debug:\n",
    "                    print(f\"         Ligne FiO2 identifi√©e {row_idx}: {row_text[:60]}...\")\n",
    "\n",
    "        # √âTAPE 2: Chercher les pourcentages dans ces lignes et adjacentes\n",
    "        for row_idx in fio2_indicator_rows:\n",
    "            # Cherche dans la ligne courante et les 2 suivantes\n",
    "            for offset in range(0, 3):\n",
    "                check_row = row_idx + offset\n",
    "                if check_row >= len(df):\n",
    "                    continue\n",
    "                    \n",
    "                row = df.iloc[check_row]\n",
    "                \n",
    "                for col_idx, cell in enumerate(row):\n",
    "                    cell_str = str(cell).strip()\n",
    "                    percentage_match = re.search(r\"(\\d+)\\s*%\", cell_str)\n",
    "                    \n",
    "                    if percentage_match:\n",
    "                        percentage = float(percentage_match.group(1))\n",
    "                        \n",
    "                        # Validation plus stricte\n",
    "                        is_valid = False\n",
    "                        if section_type == \"FiO2<100\" and 21 <= percentage < 100:\n",
    "                            is_valid = True\n",
    "                        elif section_type == \"FiO2=100\" and percentage == 100:\n",
    "                            is_valid = True\n",
    "                        \n",
    "                        if is_valid:\n",
    "                            percentages[col_idx] = percentage\n",
    "                            if self.debug:\n",
    "                                print(f\"         ‚Üí FiO2 {percentage}% pour col {col_idx}\")\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"         Pourcentages FiO2 finaux: {percentages}\")\n",
    "\n",
    "        return percentages\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _get_fio2_for_column(\n",
    "        self,\n",
    "        percentages: Dict[int, float],\n",
    "        col_idx: int,\n",
    "        section_type: str\n",
    "    ) -> float:\n",
    "        \"\"\"D√©termine le pourcentage FiO2 pour une colonne sp√©cifique.\"\"\"\n",
    "        if col_idx in percentages:\n",
    "            return percentages[col_idx]\n",
    "\n",
    "        # Valeurs par d√©faut selon le type\n",
    "        if section_type == \"FiO2=100\":\n",
    "            return 100.0\n",
    "        else:\n",
    "            return 21.0  # Air ambiant par d√©faut\n",
    "\n",
    "\n",
    "\n",
    "    def _find_medical_parameter_rows(self, df: pd.DataFrame) -> Dict[str, int]:\n",
    "        \"\"\"Trouve les lignes contenant les param√®tres m√©dicaux avec am√©lioration.\"\"\"\n",
    "        param_rows = {}\n",
    "\n",
    "        # Param√®tres √† chercher avec patterns am√©lior√©s\n",
    "        param_patterns = {\n",
    "            'pH': r'\\.{0,5}ph\\b(?!\\w)|ph\\s*[:=]|fio2.*ph',\n",
    "            'PaCO2': r'\\.{0,5}paco2\\b|paco2\\s*[:=]',\n",
    "            'PaO2': r'\\.{0,5}pao2\\b|pao2\\s*[:=]', \n",
    "            'SaO2': r'\\.{0,5}sao2\\b|sao2\\s*[:=]',\n",
    "            'CO3H': r'\\.{0,5}co3h-?\\b|co3h\\s*[:=]',\n",
    "            'PEEP': r'\\.{0,5}peep\\b|peep\\s*[:=]'\n",
    "        }\n",
    "\n",
    "        for row_idx, row in df.iterrows():\n",
    "            row_text = ' '.join(str(cell) for cell in row if str(cell).strip()).lower()\n",
    "\n",
    "            if self.debug and any(param.lower() in row_text for param in [\"ph\", \"paco2\", \"pao2\", \"sao2\", \"co3h\", \"peep\"]):\n",
    "                print(f\"      Ligne {row_idx}: {row_text[:80]}...\")\n",
    "\n",
    "            # Priorit√© stricte : un seul param√®tre par ligne\n",
    "            for param_name, pattern in param_patterns.items():\n",
    "                if re.search(pattern, row_text):\n",
    "                    # V√©rifie qu'il y a des donn√©es num√©riques dans cette ligne ou les suivantes\n",
    "                    has_data_nearby = self._check_data_nearby(df, row_idx)\n",
    "                    if has_data_nearby:\n",
    "                        param_rows[param_name] = row_idx\n",
    "                        if self.debug:\n",
    "                            print(f\"      ‚Üí {param_name} trouv√© ligne {row_idx}\")\n",
    "                        break\n",
    "\n",
    "        return param_rows\n",
    "\n",
    "    def _check_data_nearby(self, df: pd.DataFrame, row_idx: int) -> bool:\n",
    "        \"\"\"V√©rifie s'il y a des donn√©es num√©riques pr√®s de cette ligne.\"\"\"\n",
    "        # Cherche dans un rayon de 3 lignes\n",
    "        for offset in range(-2, 4):\n",
    "            check_row = row_idx + offset\n",
    "            if 0 <= check_row < len(df):\n",
    "                row = df.iloc[check_row]\n",
    "                row_text = ' '.join(str(cell) for cell in row if str(cell).strip())\n",
    "                \n",
    "                # Cherche des patterns num√©riques m√©dicaux\n",
    "                if re.search(r'\\d+(?:\\.\\d+)?\\s*(?:mmhg|mmol|%|cm)', row_text.lower()):\n",
    "                    return True\n",
    "                if re.search(r'\\d+\\.\\d{2}', row_text):  # pH style\n",
    "                    return True\n",
    "        \n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _extract_numeric_value(self, text: str) -> Optional[float]:\n",
    "        \"\"\"Extrait une valeur num√©rique d'une cha√Æne.\"\"\"\n",
    "        if not text or text.strip() == '' or text.strip().lower() in ['nan', '']:\n",
    "            return None\n",
    "\n",
    "        # Nettoie le texte (garde seulement chiffres, points, virgules)\n",
    "        cleaned = re.sub(r'[^\\d\\.\\,\\-]', ' ', str(text))\n",
    "\n",
    "        # Cherche des nombres d√©cimaux\n",
    "        decimal_matches = re.findall(r'\\d+[,\\.]\\d+', cleaned)\n",
    "        if decimal_matches:\n",
    "            value_str = decimal_matches[0].replace(',', '.')\n",
    "            try:\n",
    "                return float(value_str)\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        # Cherche des entiers\n",
    "        int_matches = re.findall(r'\\d+', cleaned)\n",
    "        if int_matches:\n",
    "            try:\n",
    "                return float(int_matches[0])\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "    def _select_best_data_smart(self, all_data: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        \"\"\"Version corrig√©e de la s√©lection avec priorit√© temporelle.\"\"\"\n",
    "        if not all_data:\n",
    "            return {}\n",
    "\n",
    "        def parse_timestamp(entry: Dict) -> datetime:\n",
    "            ts_str = entry.get('timestamp', '')\n",
    "            try:\n",
    "                return datetime.strptime(ts_str, \"%d/%m/%Y %H:%M\")\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    return datetime.strptime(ts_str, \"%d/%m/%Y\")\n",
    "                except ValueError:\n",
    "                    return datetime.min\n",
    "\n",
    "        def priority_score(entry: Dict) -> Tuple:\n",
    "            timestamp = parse_timestamp(entry)\n",
    "            # CORRECTION: Priorit√© au timestamp le plus r√©cent en PREMIER\n",
    "            # Puis FiO2=100 > FiO2<100\n",
    "            # Puis FiO2% le plus √©lev√©\n",
    "            fio2_type_priority = 2 if entry.get('fio2_type') == 'FiO2=100' else 1\n",
    "            fio2_percentage = entry.get('fio2_percentage', 0)\n",
    "            return (timestamp, fio2_type_priority, fio2_percentage)\n",
    "\n",
    "        # Trie par priorit√© (le plus √©lev√© en premier)\n",
    "        sorted_data = sorted(all_data, key=priority_score, reverse=True)\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"\\nüîÑ S√©lection parmi {len(all_data)} entr√©es:\")\n",
    "            for i, entry in enumerate(sorted_data[:3]):  # Affiche top 3\n",
    "                score = priority_score(entry)\n",
    "                print(f\"   {i+1}. {entry.get('timestamp')} | {entry.get('fio2_type')} | \"\n",
    "                    f\"{entry.get('fio2_percentage')}% | Score: {score}\")\n",
    "        \n",
    "        selected = sorted_data[0]\n",
    "\n",
    "        # Construit le r√©sultat final\n",
    "        result = {}\n",
    "        exclude_keys = {'timestamp', 'fio2_type', 'column_index'}\n",
    "\n",
    "        for key, value in selected.items():\n",
    "            if key not in exclude_keys:\n",
    "                result[key] = value\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"\\nüéØ Donn√©es s√©lectionn√©es:\")\n",
    "            print(f\"   Timestamp: {selected.get('timestamp')} (le plus r√©cent)\")\n",
    "            print(f\"   Type: {selected.get('fio2_type')}\")\n",
    "            print(f\"   FiO2: {selected.get('fio2_percentage')}%\")\n",
    "            print(f\"   Param√®tres: {len([k for k in result.keys() if k != 'fio2_percentage'])}\")\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def validate_gds_data(self, data: Dict[str, float]) -> List[str]:\n",
    "        \"\"\"Valide les donn√©es extraites.\"\"\"\n",
    "        warnings = []\n",
    "\n",
    "        ranges = {\n",
    "            \"pH\": (6.8, 8.0),\n",
    "            \"PaCO2\": (10, 100),\n",
    "            \"PaO2\": (30, 600),\n",
    "            \"SaO2\": (70, 100),\n",
    "            \"CO3H\": (10, 35),\n",
    "            \"PEEP\": (0, 20),\n",
    "            \"fio2_percentage\": (21, 100)\n",
    "        }\n",
    "\n",
    "        for param, (min_val, max_val) in ranges.items():\n",
    "            if param in data:\n",
    "                value = data[param]\n",
    "                if not (min_val <= value <= max_val):\n",
    "                    warnings.append(f\"{param} = {value} hors plage ({min_val}-{max_val})\")\n",
    "\n",
    "        return warnings\n",
    "\n",
    "\n",
    "# Fonctions de test\n",
    "def test_smart_gds_extractor(pdf_path: str, pages: str = \"all\", debug: bool = True):\n",
    "    \"\"\"Teste l'extracteur GDS intelligent.\"\"\"\n",
    "    print(f\"üß† Test Smart GDS Extractor\")\n",
    "    print(f\"üìÅ Fichier: {pdf_path}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    if not Path(pdf_path).exists():\n",
    "        print(f\"‚ùå Fichier non trouv√©: {pdf_path}\")\n",
    "        return None\n",
    "\n",
    "    # Initialise l'extracteur\n",
    "    extractor = SmartGDSExtractor(debug=debug)\n",
    "\n",
    "    # Extrait les donn√©es\n",
    "    print(\"\\nüîÑ Extraction avec logique intelligente...\")\n",
    "    gds_data = extractor.extract_gds_data_from_pdf(pdf_path, pages)\n",
    "\n",
    "    # Affiche les r√©sultats\n",
    "    print(f\"\\nüìä R√©sultats finaux:\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    if gds_data:\n",
    "        print(\"‚úÖ Donn√©es GDS extraites avec succ√®s!\")\n",
    "        for param, value in gds_data.items():\n",
    "            print(f\"   {param:20}: {value}\")\n",
    "\n",
    "        # Validation\n",
    "        warnings = extractor.validate_gds_data(gds_data)\n",
    "\n",
    "        if warnings:\n",
    "            print(f\"\\n‚ö†Ô∏è  Avertissements:\")\n",
    "            for warning in warnings:\n",
    "                print(f\"   ‚Ä¢ {warning}\")\n",
    "        else:\n",
    "            print(f\"\\n‚úÖ Toutes les valeurs sont valides\")\n",
    "    else:\n",
    "        print(\"‚ùå Aucune donn√©e extraite\")\n",
    "\n",
    "    return gds_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Test Smart GDS Extractor\n",
      "üìÅ Fichier: C:\\Users\\benysar\\Documents\\GitHub\\pulmo-cristal\\sandbox\\sample_pdfs\\53628.pdf\n",
      "============================================================\n",
      "\n",
      "üîÑ Extraction avec logique intelligente...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 09:50:16,651 - SmartGDSExtractor - INFO - Trouv√© 19 tables\n",
      "2025-08-27 09:50:16,658 - SmartGDSExtractor - WARNING - Aucun split FiO2=100 d√©tect√©, analyse comme section mixte\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Table GDS s√©lectionn√©e (score: 13)\n",
      "   Shape: (9, 4)\n",
      "\n",
      "üîç Traitement table GDS:\n",
      "   Shape originale: (9, 4)\n",
      "   üìÖ Headers extraits: 3\n",
      "      Col 1: 05/01/2009 12:00\n",
      "      Col 2: 05/01/2009 15:40\n",
      "      Col 3: 06/01/2009 03:45\n",
      "   üîç Recherche du split FiO2=100 dans 9 lignes\n",
      "      Ligne 0: Gaz du sang FiO2 <100% et FiO2=100%\n",
      "      Ligne 1: 05/01/2009 12:00 05/01/2009 15:40 06/01/2009 03:45\n",
      "      Ligne 2: FiO2<100 : pourcentage : 60 %\n",
      "      Ligne 3: ...pH 7.48\n",
      "      Ligne 4: ...PaCO2 30 mmHg\n",
      "      Ligne 5: ...PaO2 236 mmHg\n",
      "      Ligne 6: ...CO3H- 23 mmol/l\n",
      "      Ligne 7: ...SaO2 99.6 %\n",
      "      Ligne 8: ...PEEP 5 cm d'eau\n",
      "      Ligne 2: 1 valeurs m√©dicales\n",
      "      Ligne 3: 1 valeurs m√©dicales\n",
      "      Ligne 4: 1 valeurs m√©dicales\n",
      "      Ligne 5: 1 valeurs m√©dicales\n",
      "      Ligne 6: 1 valeurs m√©dicales\n",
      "      Ligne 7: 1 valeurs m√©dicales\n",
      "      Ligne 8: 1 valeurs m√©dicales\n",
      "   ‚ùå Aucun split FiO2=100 trouv√©\n",
      "   üîÑ Analyse intelligente des colonnes par type FiO2\n",
      "   üîç Analyse colonnes pour Mixte:\n",
      "      DataFrame shape: (9, 4)\n",
      "      Col 1: nums=1, units=0, timestamps=True, pH=False -> GARD√âE\n",
      "         Contenu: 05/01/2009 12:00...\n",
      "      Col 2: nums=8, units=6, timestamps=True, pH=True -> GARD√âE\n",
      "         Contenu: 05/01/2009 15:40 60 % 7.48 30 mmhg 236 mmhg 23 mmol/l 99.6 % 5 cm d'eau...\n",
      "      Col 3: nums=1, units=0, timestamps=True, pH=False -> GARD√âE\n",
      "         Contenu: 06/01/2009 03:45...\n",
      "   üßπ Mixte nettoyage: (9, 4) -> (9, 4)\n",
      "      Colonnes gard√©es: [0, 1, 2, 3]\n",
      "      Headers finaux: [(1, '05/01/2009', '12:00'), (2, '05/01/2009', '15:40'), (3, '06/01/2009', '03:45')]\n",
      "   üìä Analyse colonne 1 (05/01/2009 12:00)\n",
      "      Colonne 1: 0 valeurs m√©dicales, pourcentage: None%\n",
      "      ‚Üí Aucune donn√©es dans cette colonne\n",
      "   üìä Analyse colonne 2 (05/01/2009 15:40)\n",
      "      Colonne 2: 7 valeurs m√©dicales, pourcentage: 60.0%\n",
      "      ‚Üí Type d√©tect√©: FiO2<100, FiO2: 60.0%\n",
      "      Ligne 3: ...ph 7.48...\n",
      "      ‚Üí pH trouv√© ligne 3\n",
      "      Ligne 4: ...paco2 30 mmhg...\n",
      "      ‚Üí PaCO2 trouv√© ligne 4\n",
      "      Ligne 5: ...pao2 236 mmhg...\n",
      "      ‚Üí PaO2 trouv√© ligne 5\n",
      "      Ligne 6: ...co3h- 23 mmol/l...\n",
      "      ‚Üí CO3H trouv√© ligne 6\n",
      "      Ligne 7: ...sao2 99.6 %...\n",
      "      ‚Üí SaO2 trouv√© ligne 7\n",
      "      Ligne 8: ...peep 5 cm d'eau...\n",
      "      ‚Üí PEEP trouv√© ligne 8\n",
      "         Analyse cellule [3, 2] pour pH: '7.48'\n",
      "         ‚Üí Valeur extraite pour pH: 7.48\n",
      "         Analyse cellule [4, 2] pour PaCO2: '30 mmHg'\n",
      "         ‚Üí Trouv√© PaCO2 avec mmHg: 30.0\n",
      "         ‚Üí Valeur extraite pour PaCO2: 30.0\n",
      "         Analyse cellule [5, 2] pour PaO2: '236 mmHg'\n",
      "         ‚Üí Trouv√© PaO2 avec mmHg: 236.0\n",
      "         ‚Üí Valeur extraite pour PaO2: 236.0\n",
      "         Analyse cellule [6, 2] pour CO3H: '23 mmol/l'\n",
      "         ‚Üí Valeur extraite pour CO3H: 23.0\n",
      "         Analyse cellule [7, 2] pour SaO2: '99.6 %'\n",
      "         ‚Üí Valeur extraite pour SaO2: 99.6\n",
      "         Analyse cellule [8, 2] pour PEEP: '5 cm d'eau'\n",
      "         ‚Üí Valeur extraite pour PEEP: 5.0\n",
      "      ‚úÖ 05/01/2009 15:40 (FiO2<100, 60.0%): 6 params [pH, PaCO2, PaO2, CO3H, SaO2, PEEP]\n",
      "   üìä Analyse colonne 3 (06/01/2009 03:45)\n",
      "      Colonne 3: 0 valeurs m√©dicales, pourcentage: None%\n",
      "      ‚Üí Aucune donn√©es dans cette colonne\n",
      "\n",
      "üîÑ S√©lection parmi 1 entr√©es:\n",
      "   1. 05/01/2009 15:40 | FiO2<100 | 60.0% | Score: (datetime.datetime(2009, 1, 5, 15, 40), 1, 60.0)\n",
      "\n",
      "üéØ Donn√©es s√©lectionn√©es:\n",
      "   Timestamp: 05/01/2009 15:40 (le plus r√©cent)\n",
      "   Type: FiO2<100\n",
      "   FiO2: 60.0%\n",
      "   Param√®tres: 6\n",
      "\n",
      "üìä R√©sultats finaux:\n",
      "========================================\n",
      "‚úÖ Donn√©es GDS extraites avec succ√®s!\n",
      "   fio2_percentage     : 60.0\n",
      "   pH                  : 7.48\n",
      "   PaCO2               : 30.0\n",
      "   PaO2                : 236.0\n",
      "   CO3H                : 23.0\n",
      "   SaO2                : 99.6\n",
      "   PEEP                : 5.0\n",
      "\n",
      "‚úÖ Toutes les valeurs sont valides\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Pour tester\n",
    "PDF_PATH = r\"C:\\Users\\benysar\\Documents\\GitHub\\pulmo-cristal\\sandbox\\sample_pdfs\\53628.pdf\"  # Changez ce chemin\n",
    "result = test_smart_gds_extractor(PDF_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
