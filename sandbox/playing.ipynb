{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the pulmo-cristal Package\n",
    "## This guide shows how to use the pulmo-cristal package for extracting and processing data from donor PDF documents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pulmo-cristal 0.1.0\n",
      "Uninstalling pulmo-cristal-0.1.0:\n",
      "  Successfully uninstalled pulmo-cristal-0.1.0\n",
      "Found existing installation: camelot-py 1.0.0\n",
      "Uninstalling camelot-py-1.0.0:\n",
      "  Successfully uninstalled camelot-py-1.0.0\n"
     ]
    }
   ],
   "source": [
    "# Install the package from GitHub\n",
    "!pip uninstall pulmo-cristal -y\n",
    "!pip uninstall camelot-py -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/drci-foch/pulmo-cristal.git\n",
      "  Cloning https://github.com/drci-foch/pulmo-cristal.git to c:\\users\\benysar\\appdata\\local\\temp\\pip-req-build-3g75ack5\n",
      "  Resolved https://github.com/drci-foch/pulmo-cristal.git to commit 329e1f51395b333e31bd2b5d6993aa96a315c2e7\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: PyPDF2>=3.0.0 in c:\\users\\benysar\\documents\\github\\pulmo-cristal\\venv\\lib\\site-packages (from pulmo-cristal==0.1.0) (3.0.1)\n",
      "Collecting camelot-py>=1.0.0 (from pulmo-cristal==0.1.0)\n",
      "  Using cached camelot_py-1.0.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: opencv-python-headless>=4.5.0 in c:\\users\\benysar\\documents\\github\\pulmo-cristal\\venv\\lib\\site-packages (from pulmo-cristal==0.1.0) (4.11.0.86)\n",
      "Requirement already satisfied: ghostscript>=0.7 in c:\\users\\benysar\\documents\\github\\pulmo-cristal\\venv\\lib\\site-packages (from pulmo-cristal==0.1.0) (0.7)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\benysar\\documents\\github\\pulmo-cristal\\venv\\lib\\site-packages (from pulmo-cristal==0.1.0) (2.2.4)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\benysar\\documents\\github\\pulmo-cristal\\venv\\lib\\site-packages (from pulmo-cristal==0.1.0) (2.2.3)\n",
      "Requirement already satisfied: click>=8.0.1 in c:\\users\\benysar\\documents\\github\\pulmo-cristal\\venv\\lib\\site-packages (from camelot-py>=1.0.0->pulmo-cristal==0.1.0) (8.1.8)\n",
      "Requirement already satisfied: chardet>=5.1.0 in c:\\users\\benysar\\documents\\github\\pulmo-cristal\\venv\\lib\\site-packages (from camelot-py>=1.0.0->pulmo-cristal==0.1.0) (5.2.0)\n",
      "Requirement already satisfied: openpyxl>=3.1.0 in c:\\users\\benysar\\documents\\github\\pulmo-cristal\\venv\\lib\\site-packages (from camelot-py>=1.0.0->pulmo-cristal==0.1.0) (3.1.5)\n",
      "Requirement already satisfied: pdfminer-six>=20240706 in c:\\users\\benysar\\documents\\github\\pulmo-cristal\\venv\\lib\\site-packages (from camelot-py>=1.0.0->pulmo-cristal==0.1.0) (20250327)\n",
      "Requirement already satisfied: pypdf<4.0,>=3.17 in c:\\users\\benysar\\documents\\github\\pulmo-cristal\\venv\\lib\\site-packages (from camelot-py>=1.0.0->pulmo-cristal==0.1.0) (3.17.4)\n",
      "Requirement already satisfied: tabulate>=0.9.0 in c:\\users\\benysar\\documents\\github\\pulmo-cristal\\venv\\lib\\site-packages (from camelot-py>=1.0.0->pulmo-cristal==0.1.0) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\benysar\\documents\\github\\pulmo-cristal\\venv\\lib\\site-packages (from camelot-py>=1.0.0->pulmo-cristal==0.1.0) (4.13.1)\n",
      "Requirement already satisfied: pypdfium2>=4 in c:\\users\\benysar\\documents\\github\\pulmo-cristal\\venv\\lib\\site-packages (from camelot-py>=1.0.0->pulmo-cristal==0.1.0) (4.30.1)\n",
      "Requirement already satisfied: setuptools>=38.6.0 in c:\\users\\benysar\\documents\\github\\pulmo-cristal\\venv\\lib\\site-packages (from ghostscript>=0.7->pulmo-cristal==0.1.0) (75.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\benysar\\documents\\github\\pulmo-cristal\\venv\\lib\\site-packages (from pandas>=1.3.0->pulmo-cristal==0.1.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\benysar\\documents\\github\\pulmo-cristal\\venv\\lib\\site-packages (from pandas>=1.3.0->pulmo-cristal==0.1.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\benysar\\documents\\github\\pulmo-cristal\\venv\\lib\\site-packages (from pandas>=1.3.0->pulmo-cristal==0.1.0) (2025.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\benysar\\documents\\github\\pulmo-cristal\\venv\\lib\\site-packages (from click>=8.0.1->camelot-py>=1.0.0->pulmo-cristal==0.1.0) (0.4.6)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\benysar\\documents\\github\\pulmo-cristal\\venv\\lib\\site-packages (from openpyxl>=3.1.0->camelot-py>=1.0.0->pulmo-cristal==0.1.0) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\benysar\\documents\\github\\pulmo-cristal\\venv\\lib\\site-packages (from pdfminer-six>=20240706->camelot-py>=1.0.0->pulmo-cristal==0.1.0) (3.4.1)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\benysar\\documents\\github\\pulmo-cristal\\venv\\lib\\site-packages (from pdfminer-six>=20240706->camelot-py>=1.0.0->pulmo-cristal==0.1.0) (44.0.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\benysar\\documents\\github\\pulmo-cristal\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->pulmo-cristal==0.1.0) (1.17.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\benysar\\documents\\github\\pulmo-cristal\\venv\\lib\\site-packages (from cryptography>=36.0.0->pdfminer-six>=20240706->camelot-py>=1.0.0->pulmo-cristal==0.1.0) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\benysar\\documents\\github\\pulmo-cristal\\venv\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer-six>=20240706->camelot-py>=1.0.0->pulmo-cristal==0.1.0) (2.22)\n",
      "Using cached camelot_py-1.0.0-py3-none-any.whl (66 kB)\n",
      "Building wheels for collected packages: pulmo-cristal\n",
      "  Building wheel for pulmo-cristal (setup.py): started\n",
      "  Building wheel for pulmo-cristal (setup.py): finished with status 'done'\n",
      "  Created wheel for pulmo-cristal: filename=pulmo_cristal-0.1.0-py3-none-any.whl size=47973 sha256=db723b6a9d50a05d09fa8c6836f604e00572d4bedd1bf47bbc0a8a659a14cbbd\n",
      "  Stored in directory: C:\\Users\\benysar\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-s5e6x4mz\\wheels\\a5\\e9\\92\\577bc5da6aeadbf08021b11744327874c0d39e50b4460d7346\n",
      "Successfully built pulmo-cristal\n",
      "Installing collected packages: camelot-py, pulmo-cristal\n",
      "Successfully installed camelot-py-1.0.0 pulmo-cristal-0.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/drci-foch/pulmo-cristal.git 'C:\\Users\\benysar\\AppData\\Local\\Temp\\pip-req-build-3g75ack5'\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/drci-foch/pulmo-cristal.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "Let's check if the package is correctly installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulmo-cristal 0.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benysar\\Documents\\GitHub\\pulmo-cristal\\venv\\lib\\site-packages\\pypdf\\_crypt_providers\\_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n",
      "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n"
     ]
    }
   ],
   "source": [
    "# Check the package version\n",
    "!pulmo-cristal --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: pulmo-cristal [-h] [--version] [--verbose]\n",
      "                     {extract,list,convert,validate} ...\n",
      "\n",
      "Extract data from donor PDF documents.\n",
      "\n",
      "positional arguments:\n",
      "  {extract,list,convert,validate}\n",
      "                        Command to execute\n",
      "    extract             Extract data from PDF files\n",
      "    list                List PDF files in a directory\n",
      "    convert             Convert between output formats\n",
      "    validate            Validate extracted data\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --version, -V         show program's version number and exit\n",
      "  --verbose, -v         Increase verbosity (can be used multiple times)\n",
      "                        (default: 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benysar\\Documents\\GitHub\\pulmo-cristal\\venv\\lib\\site-packages\\pypdf\\_crypt_providers\\_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n",
      "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n"
     ]
    }
   ],
   "source": [
    "# View available commands\n",
    "!pulmo-cristal --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding PDF Files\n",
    "First, let's see what PDF files we have available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_pdfs/\n",
      "├── subfolder_test/\n",
      "│   └── patient3.pdf\n",
      "├── patient1.pdf\n",
      "└── patient2.pdf\n",
      "\n",
      "Total: 1 directories, 3 files\n"
     ]
    }
   ],
   "source": [
    "from pulmo_cristal.utils import find_pdf_files, list_directory_tree\n",
    "import os\n",
    "\n",
    "# Set the path to your directory containing existing PDFs\n",
    "pdf_dir = \"./sample_pdfs\"  # Change this to your actual path\n",
    "\n",
    "# Print directory tree to see the structure\n",
    "tree = list_directory_tree(pdf_dir, max_depth=2, file_types=[\".pdf\"])\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 PDF files\n",
      "\n",
      "Sample of PDF files found:\n",
      "  - sample_pdfs\\patient1.pdf\n",
      "  - sample_pdfs\\patient2.pdf\n",
      "  - sample_pdfs\\subfolder_test\\patient3.pdf\n"
     ]
    }
   ],
   "source": [
    "# Find all PDF files in the directory\n",
    "pdf_files = find_pdf_files(pdf_dir, recursive=True)\n",
    "print(f\"Found {len(pdf_files)} PDF files\")\n",
    "\n",
    "# Display the first few files\n",
    "if pdf_files:\n",
    "    print(\"\\nSample of PDF files found:\")\n",
    "    for pdf in pdf_files[:5]:\n",
    "        print(f\"  - {pdf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Data from a PDF\n",
    "Now let's extract data from our sample PDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 16:41:10,578 - DonorPDFExtractor - INFO - Extracting text from PDF: sample_pdfs\\patient1.pdf\n",
      "2025-04-08 16:41:10,581 - DonorPDFExtractor - INFO - PDF contains 21 pages\n",
      "2025-04-08 16:41:10,598 - DonorPDFExtractor - INFO - Page 1/21: Extracted 1377 characters\n",
      "2025-04-08 16:41:10,600 - DonorPDFExtractor - INFO - Page 2/21: Extracted 92 characters\n",
      "2025-04-08 16:41:10,608 - DonorPDFExtractor - INFO - Page 3/21: Extracted 1444 characters\n",
      "2025-04-08 16:41:10,616 - DonorPDFExtractor - INFO - Page 4/21: Extracted 719 characters\n",
      "2025-04-08 16:41:10,621 - DonorPDFExtractor - INFO - Page 5/21: Extracted 645 characters\n",
      "2025-04-08 16:41:10,623 - DonorPDFExtractor - INFO - Page 6/21: Extracted 262 characters\n",
      "2025-04-08 16:41:10,629 - DonorPDFExtractor - INFO - Page 7/21: Extracted 490 characters\n",
      "2025-04-08 16:41:10,634 - DonorPDFExtractor - INFO - Page 8/21: Extracted 367 characters\n",
      "2025-04-08 16:41:10,644 - DonorPDFExtractor - INFO - Page 9/21: Extracted 951 characters\n",
      "2025-04-08 16:41:10,653 - DonorPDFExtractor - INFO - Page 10/21: Extracted 772 characters\n",
      "2025-04-08 16:41:10,662 - DonorPDFExtractor - INFO - Page 11/21: Extracted 596 characters\n",
      "2025-04-08 16:41:10,672 - DonorPDFExtractor - INFO - Page 12/21: Extracted 852 characters\n",
      "2025-04-08 16:41:10,681 - DonorPDFExtractor - INFO - Page 13/21: Extracted 926 characters\n",
      "2025-04-08 16:41:10,690 - DonorPDFExtractor - INFO - Page 14/21: Extracted 1097 characters\n",
      "2025-04-08 16:41:10,695 - DonorPDFExtractor - INFO - Page 15/21: Extracted 256 characters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: sample_pdfs\\patient1.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 16:41:10,710 - DonorPDFExtractor - INFO - Page 16/21: Extracted 808 characters\n",
      "2025-04-08 16:41:10,738 - DonorPDFExtractor - INFO - Page 17/21: Extracted 1624 characters\n",
      "2025-04-08 16:41:10,740 - DonorPDFExtractor - INFO - Page 18/21: Extracted 134 characters\n",
      "2025-04-08 16:41:10,750 - DonorPDFExtractor - INFO - Page 19/21: Extracted 1065 characters\n",
      "2025-04-08 16:41:10,760 - DonorPDFExtractor - INFO - Page 20/21: Extracted 1009 characters\n",
      "2025-04-08 16:41:10,762 - DonorPDFExtractor - INFO - Page 21/21: Extracted 203 characters\n",
      "2025-04-08 16:41:10,762 - DonorPDFExtractor - INFO - Total extracted text: 15729 characters\n",
      "2025-04-08 16:41:10,764 - DonorPDFExtractor - WARNING - Pattern group 'serologies' not found. Skipping section.\n",
      "2025-04-08 16:41:10,764 - DonorPDFExtractor - WARNING - Pattern group 'morphologie' not found. Skipping section.\n",
      "2025-04-08 16:41:10,769 - HLAExtractor - INFO - Extracting HLA data from sample_pdfs\\patient1.pdf using original approach\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted Donor Information:\n",
      "  num_cristal: 175394\n",
      "  type_donneur: Donneur prélevé, organe greffé\n",
      "Coeur Battant (SME)\n",
      "  age: 67\n",
      "  sexe: M\n",
      "  groupe_sanguin: o-\n",
      "  date_naissance: 03/12/1952\n",
      "  taille: 173\n",
      "  poids: 78\n",
      "  date_clampage: 05/01/2020\n",
      "  etiologie: Traumatique Non A.V.P.\n",
      "  duree_ventilation: 1\n",
      "  hla_extraction_status: OK\n",
      "\n",
      "Extracted HLA Data:\n",
      "  A1: 2\n",
      "  A2: 24\n",
      "  B1: 35\n",
      "  B2: 51\n",
      "  C1: 4\n",
      "  C2: 14\n",
      "  DR1: 11\n",
      "  DR2: 16\n",
      "  DQA: 5\n",
      "  DQB: 7\n",
      "  DP1: 4\n",
      "  DP2: 0\n"
     ]
    }
   ],
   "source": [
    "from pulmo_cristal.extractors import DonorPDFExtractor, HLAExtractor\n",
    "\n",
    "# Select a sample PDF to process\n",
    "sample_pdf = pdf_files[0] if pdf_files else None\n",
    "\n",
    "if sample_pdf:\n",
    "    print(f\"Processing: {sample_pdf}\")\n",
    "\n",
    "    # Initialize extractors\n",
    "    donor_extractor = DonorPDFExtractor()\n",
    "    hla_extractor = HLAExtractor()\n",
    "\n",
    "    try:\n",
    "        # Extract donor data\n",
    "        donor_data = donor_extractor.extract_donor_data(sample_pdf)\n",
    "\n",
    "        # Extract HLA data\n",
    "        hla_data, hla_status = hla_extractor.extract_hla_data(sample_pdf)\n",
    "\n",
    "        # Add HLA data to donor data\n",
    "        donor_data[\"informations_donneur\"][\"hla\"] = hla_data\n",
    "        donor_data[\"informations_donneur\"][\"hla_extraction_status\"] = hla_status\n",
    "\n",
    "        # Display extracted data\n",
    "        print(\"\\nExtracted Donor Information:\")\n",
    "        for key, value in donor_data[\"informations_donneur\"].items():\n",
    "            if key != \"hla\":  # Skip HLA for now\n",
    "                print(f\"  {key}: {value}\")\n",
    "\n",
    "        print(\"\\nExtracted HLA Data:\")\n",
    "        for key, value in hla_data.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting data: {e}\")\n",
    "else:\n",
    "    print(\"No PDF files found to process\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to a Structured Model\n",
    "Convert the raw extracted data to a structured Donneur model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donor ID: 175394\n",
      "Donor Type: DonneurType.INCONNU\n",
      "Age: 67\n",
      "Sex: SexeType.HOMME\n",
      "\n",
      "Validation Result: Valid\n"
     ]
    }
   ],
   "source": [
    "from pulmo_cristal.models import Donneur\n",
    "\n",
    "if \"donor_data\" in locals():\n",
    "    try:\n",
    "        # Convert to Donneur model\n",
    "        donneur = Donneur.from_dict(donor_data)\n",
    "\n",
    "        # Display basic model information\n",
    "        print(f\"Donor ID: {donneur.id}\")\n",
    "        print(f\"Donor Type: {donneur.type_donneur}\")\n",
    "        print(f\"Age: {donneur.age}\")\n",
    "        print(f\"Sex: {donneur.sexe}\")\n",
    "\n",
    "        # Validate the model\n",
    "        is_valid = donneur.validate()\n",
    "        print(f\"\\nValidation Result: {'Valid' if is_valid else 'Invalid'}\")\n",
    "        if not is_valid and hasattr(donneur, \"validation_errors\"):\n",
    "            print(\"Validation Errors:\")\n",
    "            for error in donneur.validation_errors:\n",
    "                print(f\"  - {error}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting to model: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting Data to JSON and CSV\n",
    "Now let's export the extracted data to JSON and CSV formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 16:41:11,046 - DonorJSONExporter - INFO - JSON file generated successfully: output\\donor_data_20250408_164111.json\n",
      "2025-04-08 16:41:11,047 - DonorCSVExporter - INFO - CSV file generated successfully: output\\donor_data_20250408_164111.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported JSON to: ./output\\donor_data.json\n",
      "Exported CSV to: ./output\\donor_data.csv\n"
     ]
    }
   ],
   "source": [
    "from pulmo_cristal.exporters import DonorJSONExporter, DonorCSVExporter\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"./output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "if \"donor_data\" in locals():\n",
    "    # Initialize exporters\n",
    "    json_exporter = DonorJSONExporter()\n",
    "    csv_exporter = DonorCSVExporter()\n",
    "\n",
    "    try:\n",
    "        # Export to JSON\n",
    "        json_path = os.path.join(output_dir, \"donor_data.json\")\n",
    "        json_exporter.export_json([donor_data], json_path)\n",
    "        print(f\"Exported JSON to: {json_path}\")\n",
    "\n",
    "        # Export to CSV\n",
    "        csv_path = os.path.join(output_dir, \"donor_data.csv\")\n",
    "        csv_exporter.export_csv([donor_data], csv_path)\n",
    "        print(f\"Exported CSV to: {csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error exporting data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Multiple Files\n",
    "For processing all your existing PDFs in batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 16:41:11,062 - DonorPDFExtractor - INFO - Extracting text from PDF: sample_pdfs\\patient1.pdf\n",
      "2025-04-08 16:41:11,065 - DonorPDFExtractor - INFO - PDF contains 21 pages\n",
      "2025-04-08 16:41:11,081 - DonorPDFExtractor - INFO - Page 1/21: Extracted 1377 characters\n",
      "2025-04-08 16:41:11,083 - DonorPDFExtractor - INFO - Page 2/21: Extracted 92 characters\n",
      "2025-04-08 16:41:11,091 - DonorPDFExtractor - INFO - Page 3/21: Extracted 1444 characters\n",
      "2025-04-08 16:41:11,099 - DonorPDFExtractor - INFO - Page 4/21: Extracted 719 characters\n",
      "2025-04-08 16:41:11,104 - DonorPDFExtractor - INFO - Page 5/21: Extracted 645 characters\n",
      "2025-04-08 16:41:11,106 - DonorPDFExtractor - INFO - Page 6/21: Extracted 262 characters\n",
      "2025-04-08 16:41:11,111 - DonorPDFExtractor - INFO - Page 7/21: Extracted 490 characters\n",
      "2025-04-08 16:41:11,115 - DonorPDFExtractor - INFO - Page 8/21: Extracted 367 characters\n",
      "2025-04-08 16:41:11,146 - DonorPDFExtractor - INFO - Page 9/21: Extracted 951 characters\n",
      "2025-04-08 16:41:11,157 - DonorPDFExtractor - INFO - Page 10/21: Extracted 772 characters\n",
      "2025-04-08 16:41:11,166 - DonorPDFExtractor - INFO - Page 11/21: Extracted 596 characters\n",
      "2025-04-08 16:41:11,175 - DonorPDFExtractor - INFO - Page 12/21: Extracted 852 characters\n",
      "2025-04-08 16:41:11,184 - DonorPDFExtractor - INFO - Page 13/21: Extracted 926 characters\n",
      "2025-04-08 16:41:11,194 - DonorPDFExtractor - INFO - Page 14/21: Extracted 1097 characters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing batch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 16:41:11,197 - DonorPDFExtractor - INFO - Page 15/21: Extracted 256 characters\n",
      "2025-04-08 16:41:11,213 - DonorPDFExtractor - INFO - Page 16/21: Extracted 808 characters\n",
      "2025-04-08 16:41:11,222 - DonorPDFExtractor - INFO - Page 17/21: Extracted 1624 characters\n",
      "2025-04-08 16:41:11,223 - DonorPDFExtractor - INFO - Page 18/21: Extracted 134 characters\n",
      "2025-04-08 16:41:11,234 - DonorPDFExtractor - INFO - Page 19/21: Extracted 1065 characters\n",
      "2025-04-08 16:41:11,244 - DonorPDFExtractor - INFO - Page 20/21: Extracted 1009 characters\n",
      "2025-04-08 16:41:11,246 - DonorPDFExtractor - INFO - Page 21/21: Extracted 203 characters\n",
      "2025-04-08 16:41:11,247 - DonorPDFExtractor - INFO - Total extracted text: 15729 characters\n",
      "2025-04-08 16:41:11,249 - DonorPDFExtractor - WARNING - Pattern group 'serologies' not found. Skipping section.\n",
      "2025-04-08 16:41:11,249 - DonorPDFExtractor - WARNING - Pattern group 'morphologie' not found. Skipping section.\n",
      "2025-04-08 16:41:11,254 - HLAExtractor - INFO - Extracting HLA data from sample_pdfs\\patient1.pdf using original approach\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "2025-04-08 16:41:11,512 - DonorPDFExtractor - INFO - Extracting text from PDF: sample_pdfs\\patient2.pdf\n",
      "2025-04-08 16:41:11,515 - DonorPDFExtractor - INFO - PDF contains 22 pages\n",
      "2025-04-08 16:41:11,531 - DonorPDFExtractor - INFO - Page 1/22: Extracted 1224 characters\n",
      "2025-04-08 16:41:11,533 - DonorPDFExtractor - INFO - Page 2/22: Extracted 85 characters\n",
      "2025-04-08 16:41:11,542 - DonorPDFExtractor - INFO - Page 3/22: Extracted 1546 characters\n",
      "2025-04-08 16:41:11,550 - DonorPDFExtractor - INFO - Page 4/22: Extracted 720 characters\n",
      "2025-04-08 16:41:11,555 - DonorPDFExtractor - INFO - Page 5/22: Extracted 398 characters\n",
      "2025-04-08 16:41:11,559 - DonorPDFExtractor - INFO - Page 6/22: Extracted 429 characters\n",
      "2025-04-08 16:41:11,564 - DonorPDFExtractor - INFO - Page 7/22: Extracted 490 characters\n",
      "2025-04-08 16:41:11,569 - DonorPDFExtractor - INFO - Page 8/22: Extracted 367 characters\n",
      "2025-04-08 16:41:11,581 - DonorPDFExtractor - INFO - Page 9/22: Extracted 1070 characters\n",
      "2025-04-08 16:41:11,590 - DonorPDFExtractor - INFO - Page 10/22: Extracted 762 characters\n",
      "2025-04-08 16:41:11,600 - DonorPDFExtractor - INFO - Page 11/22: Extracted 608 characters\n",
      "2025-04-08 16:41:11,608 - DonorPDFExtractor - INFO - Page 12/22: Extracted 738 characters\n",
      "2025-04-08 16:41:11,616 - DonorPDFExtractor - INFO - Page 13/22: Extracted 911 characters\n",
      "2025-04-08 16:41:11,625 - DonorPDFExtractor - INFO - Page 14/22: Extracted 1259 characters\n",
      "2025-04-08 16:41:11,629 - DonorPDFExtractor - INFO - Page 15/22: Extracted 250 characters\n",
      "2025-04-08 16:41:11,651 - DonorPDFExtractor - INFO - Page 16/22: Extracted 558 characters\n",
      "2025-04-08 16:41:11,666 - DonorPDFExtractor - INFO - Page 17/22: Extracted 570 characters\n",
      "2025-04-08 16:41:11,677 - DonorPDFExtractor - INFO - Page 18/22: Extracted 2109 characters\n",
      "2025-04-08 16:41:11,679 - DonorPDFExtractor - INFO - Page 19/22: Extracted 134 characters\n",
      "2025-04-08 16:41:11,689 - DonorPDFExtractor - INFO - Page 20/22: Extracted 1062 characters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Processed: patient1.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 16:41:11,699 - DonorPDFExtractor - INFO - Page 21/22: Extracted 846 characters\n",
      "2025-04-08 16:41:11,700 - DonorPDFExtractor - INFO - Page 22/22: Extracted 99 characters\n",
      "2025-04-08 16:41:11,701 - DonorPDFExtractor - INFO - Total extracted text: 16277 characters\n",
      "2025-04-08 16:41:11,703 - DonorPDFExtractor - WARNING - Pattern group 'serologies' not found. Skipping section.\n",
      "2025-04-08 16:41:11,703 - DonorPDFExtractor - WARNING - Pattern group 'morphologie' not found. Skipping section.\n",
      "2025-04-08 16:41:11,708 - HLAExtractor - INFO - Extracting HLA data from sample_pdfs\\patient2.pdf using original approach\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "2025-04-08 16:41:11,947 - DonorPDFExtractor - INFO - Extracting text from PDF: sample_pdfs\\subfolder_test\\patient3.pdf\n",
      "2025-04-08 16:41:11,950 - DonorPDFExtractor - INFO - PDF contains 22 pages\n",
      "2025-04-08 16:41:11,965 - DonorPDFExtractor - INFO - Page 1/22: Extracted 1329 characters\n",
      "2025-04-08 16:41:11,966 - DonorPDFExtractor - INFO - Page 2/22: Extracted 85 characters\n",
      "2025-04-08 16:41:11,975 - DonorPDFExtractor - INFO - Page 3/22: Extracted 1469 characters\n",
      "2025-04-08 16:41:12,002 - DonorPDFExtractor - INFO - Page 4/22: Extracted 718 characters\n",
      "2025-04-08 16:41:12,007 - DonorPDFExtractor - INFO - Page 5/22: Extracted 611 characters\n",
      "2025-04-08 16:41:12,010 - DonorPDFExtractor - INFO - Page 6/22: Extracted 347 characters\n",
      "2025-04-08 16:41:12,015 - DonorPDFExtractor - INFO - Page 7/22: Extracted 490 characters\n",
      "2025-04-08 16:41:12,019 - DonorPDFExtractor - INFO - Page 8/22: Extracted 381 characters\n",
      "2025-04-08 16:41:12,029 - DonorPDFExtractor - INFO - Page 9/22: Extracted 1135 characters\n",
      "2025-04-08 16:41:12,038 - DonorPDFExtractor - INFO - Page 10/22: Extracted 777 characters\n",
      "2025-04-08 16:41:12,046 - DonorPDFExtractor - INFO - Page 11/22: Extracted 537 characters\n",
      "2025-04-08 16:41:12,054 - DonorPDFExtractor - INFO - Page 12/22: Extracted 778 characters\n",
      "2025-04-08 16:41:12,063 - DonorPDFExtractor - INFO - Page 13/22: Extracted 907 characters\n",
      "2025-04-08 16:41:12,073 - DonorPDFExtractor - INFO - Page 14/22: Extracted 1157 characters\n",
      "2025-04-08 16:41:12,076 - DonorPDFExtractor - INFO - Page 15/22: Extracted 209 characters\n",
      "2025-04-08 16:41:12,079 - DonorPDFExtractor - INFO - Page 16/22: Extracted 602 characters\n",
      "2025-04-08 16:41:12,092 - DonorPDFExtractor - INFO - Page 17/22: Extracted 689 characters\n",
      "2025-04-08 16:41:12,095 - DonorPDFExtractor - INFO - Page 18/22: Extracted 290 characters\n",
      "2025-04-08 16:41:12,096 - DonorPDFExtractor - INFO - Page 19/22: Extracted 134 characters\n",
      "2025-04-08 16:41:12,106 - DonorPDFExtractor - INFO - Page 20/22: Extracted 1248 characters\n",
      "2025-04-08 16:41:12,116 - DonorPDFExtractor - INFO - Page 21/22: Extracted 782 characters\n",
      "2025-04-08 16:41:12,119 - DonorPDFExtractor - INFO - Page 22/22: Extracted 477 characters\n",
      "2025-04-08 16:41:12,119 - DonorPDFExtractor - INFO - Total extracted text: 15194 characters\n",
      "2025-04-08 16:41:12,121 - DonorPDFExtractor - WARNING - Pattern group 'serologies' not found. Skipping section.\n",
      "2025-04-08 16:41:12,121 - DonorPDFExtractor - WARNING - Pattern group 'morphologie' not found. Skipping section.\n",
      "2025-04-08 16:41:12,125 - HLAExtractor - INFO - Extracting HLA data from sample_pdfs\\subfolder_test\\patient3.pdf using original approach\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Processed: patient2.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "2025-04-08 16:41:12,382 - DonorJSONExporter - INFO - JSON file generated successfully: output\\all_donors_20250408_164112.json\n",
      "2025-04-08 16:41:12,384 - DonorCSVExporter - INFO - CSV file generated successfully: output\\all_donors_20250408_164112.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Processed: patient3.pdf\n",
      "\n",
      "Processing complete:\n",
      "  - Total files: 3\n",
      "  - Successful: 3\n",
      "  - Failed: 0\n",
      "  - Total time: 1.32 seconds\n",
      "  - Avg time per file: 0.44 seconds\n",
      "Exported all data to JSON: ./output\\all_donors.json\n",
      "Exported all data to CSV: ./output\\all_donors.csv\n"
     ]
    }
   ],
   "source": [
    "from pulmo_cristal.utils import batch_process_files\n",
    "import time\n",
    "\n",
    "if pdf_files:\n",
    "    # Initialize extractors\n",
    "    donor_extractor = DonorPDFExtractor()\n",
    "    hla_extractor = HLAExtractor()\n",
    "\n",
    "    # Initialize exporters\n",
    "    json_exporter = DonorJSONExporter()\n",
    "\n",
    "    # Process in batches\n",
    "    all_data = []\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Define batch size\n",
    "    batch_size = 5  # Adjust based on your needs\n",
    "\n",
    "    for batch_idx, batch in enumerate(\n",
    "        batch_process_files(pdf_files, batch_size=batch_size)\n",
    "    ):\n",
    "        print(\n",
    "            f\"\\nProcessing batch {batch_idx + 1}/{(len(pdf_files) + batch_size - 1) // batch_size}\"\n",
    "        )\n",
    "        batch_data = []\n",
    "\n",
    "        for pdf_file in batch:\n",
    "            try:\n",
    "                # Extract donor data\n",
    "                donor_data = donor_extractor.extract_donor_data(pdf_file)\n",
    "\n",
    "                # Extract HLA data\n",
    "                hla_data, status = hla_extractor.extract_hla_data(pdf_file)\n",
    "                donor_data[\"informations_donneur\"][\"hla\"] = hla_data\n",
    "                donor_data[\"informations_donneur\"][\"hla_extraction_status\"] = status\n",
    "\n",
    "                # Add to batch\n",
    "                batch_data.append(donor_data)\n",
    "                successful += 1\n",
    "                print(f\"✓ Processed: {pdf_file.name}\")\n",
    "            except Exception as e:\n",
    "                failed += 1\n",
    "                print(f\"✗ Error processing {pdf_file.name}: {e}\")\n",
    "\n",
    "        # Add batch to all data\n",
    "        all_data.extend(batch_data)\n",
    "\n",
    "        # Save intermediate results\n",
    "        if batch_data and (batch_idx + 1) % 2 == 0:  # Save every 2 batches\n",
    "            interim_path = os.path.join(\n",
    "                output_dir, f\"donors_interim_batch_{batch_idx + 1}.json\"\n",
    "            )\n",
    "            try:\n",
    "                json_exporter.export_json(all_data, interim_path)\n",
    "                print(f\"Saved interim results to: {interim_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving interim results: {e}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    print(\"\\nProcessing complete:\")\n",
    "    print(f\"  - Total files: {len(pdf_files)}\")\n",
    "    print(f\"  - Successful: {successful}\")\n",
    "    print(f\"  - Failed: {failed}\")\n",
    "    print(f\"  - Total time: {elapsed_time:.2f} seconds\")\n",
    "    print(f\"  - Avg time per file: {elapsed_time / len(pdf_files):.2f} seconds\")\n",
    "\n",
    "    # Export all data\n",
    "    if all_data:\n",
    "        final_json_path = os.path.join(output_dir, \"all_donors.json\")\n",
    "        final_csv_path = os.path.join(output_dir, \"all_donors.csv\")\n",
    "\n",
    "        try:\n",
    "            # Export to JSON\n",
    "            json_exporter.export_json(all_data, final_json_path)\n",
    "            print(f\"Exported all data to JSON: {final_json_path}\")\n",
    "\n",
    "            # Export to CSV\n",
    "            csv_exporter = DonorCSVExporter()\n",
    "            csv_exporter.export_csv(all_data, final_csv_path)\n",
    "            print(f\"Exported all data to CSV: {final_csv_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error exporting final data: {e}\")\n",
    "else:\n",
    "    print(\"No PDF files found to process\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Command Line Interface with Your Existing PDFs\n",
    "The package also provides a command-line interface which might be easier for batch processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benysar\\Documents\\GitHub\\pulmo-cristal\\venv\\lib\\site-packages\\pypdf\\_crypt_providers\\_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n",
      "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    }
   ],
   "source": [
    "# Extract data from all PDFs using the CLI\n",
    "!pulmo-cristal extract --input {pdf_dir} --output {output_dir} --format both --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_pdfs/\n",
      "├── subfolder_test/\n",
      "│   └── patient3.pdf\n",
      "├── patient1.pdf\n",
      "└── patient2.pdf\n",
      "\n",
      "Total: 1 directories, 3 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benysar\\Documents\\GitHub\\pulmo-cristal\\venv\\lib\\site-packages\\pypdf\\_crypt_providers\\_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n",
      "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n"
     ]
    }
   ],
   "source": [
    "# List PDF files in your directory\n",
    "!pulmo-cristal list --input {pdf_dir} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
